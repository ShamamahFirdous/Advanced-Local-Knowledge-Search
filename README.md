# ğŸ” Advanced Local Knowledge Search

An **advanced, fully local Retrieval-Augmented Generation (RAG) system** that enables intelligent search and question answering over personal documents â€” with **MMR retrieval, reranking, explainability, and a polished UI**.

This project is designed to demonstrate **modern retrieval system design**, not just basic RAG.

---

## âœ¨ Key Features

* ğŸ§  **Retrieval-Augmented Generation (RAG)**
  Combines semantic search with grounded answer generation.

* ğŸ”€ **MMR-based Retrieval**
  Ensures diverse, non-redundant document chunks are retrieved.

* ğŸ· **Metadata-Aware Filtering**
  Supports filtering by document type (`pdf`, `md`, `csv`, `docx`).

* ğŸ“Š **Reranking + Retrieval Stats**
  Displays retrieved vs. used chunks and latency for transparency.

* ğŸ” **Confidence Estimation**
  Heuristic confidence score based on source diversity.

* ğŸ“š **Explainable Sources**
  Clearly shows which files and chunks contributed to the answer.

* ğŸ’» **100% Local Execution**
  No API keys, no cloud services, no external LLM calls.

---

## ğŸ“‚ Supported Document Types

Place files inside the `data/` directory:

* `.md` â€” Markdown notes
* `.pdf` â€” PDFs
* `.csv` â€” Structured tabular data
* `.docx` â€” Word documents

All documents are automatically loaded, chunked, embedded, and indexed.

---

## ğŸ—ï¸ Project Structure

```
ADVANCED-LOCAL-SEARCH/
â”‚
â”œâ”€â”€ data/                  # Input documents
â”‚   â”œâ”€â”€ notes.md
â”‚   â”œâ”€â”€ faq.csv
â”‚   â”œâ”€â”€ rag.pdf
â”‚   â””â”€â”€ intro.docx
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py              # Streamlit UI
â”‚   â”œâ”€â”€ ingest.py           # Document ingestion + vectorstore creation
â”‚   â”œâ”€â”€ retriever.py        # MMR retrieval + metadata filtering
â”‚   â”œâ”€â”€ reranker.py         # Chunk reranking logic
â”‚   â”œâ”€â”€ qa.py               # Grounded QA orchestration
â”‚   â””â”€â”€ config.py
â”‚
â”œâ”€â”€ vectorstore/            # FAISS index (generated)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/your-username/advanced-local-search.git
cd advanced-local-search
```

### 2ï¸âƒ£ Create and activate a virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ“¥ Ingest Documents

Place your documents inside `data/`, then run:

```bash
python src/ingest.py
```

This will:

* Load all documents
* Chunk text
* Generate embeddings
* Build and persist a FAISS vectorstore

---

## ğŸš€ Run the Application

### Launch the Streamlit UI:

```bash
streamlit run src/app.py
```

Then open the local URL shown in the terminal.

---

## ğŸ§ª Example Query

> **What is Retrieval-Augmented Generation?**

The system will:

1. Retrieve diverse, relevant chunks
2. Rerank them
3. Generate a grounded answer
4. Display sources, stats, and confidence

---
## ğŸ“¸ Application Output Preview

Below are example screenshots demonstrating the system in action, including the UI, answer generation, and explainability features.

### ğŸ” Search Interface
The main interface for asking questions over local documents.
![Search Interface](images/1.png)

---

### âœ… Answer Generation with Grounded Sources
An example of a generated answer, clearly grounded in retrieved document chunks.
![Answer Generation](images/2.png)

---

### ğŸ“Š Retrieval Statistics & Confidence
Displays retrieval metrics, reranking details, and confidence estimation for transparency.
![Stats and Confidence](images/3.png)

## ğŸ§  Why This Project Matters

This project goes **beyond basic RAG demos** by focusing on:

* Retrieval quality (MMR, reranking)
* Transparency and explainability
* Real-world document messiness
* UI and product-level polish
* Local-first, privacy-preserving design

It reflects **how production knowledge search systems are actually built**.

---

### Example Questions You Can Ask
- Combine insights from multiple documents to explain this concept.
- Which sources were used to answer this question?
- Answer this using only PDF documents.
- How confident is the system in this answer?

## ğŸ”® Future Extensions (Optional)

* JSON / HTML document support
* Query history panel
* Export answers as Markdown / JSON
* Keyword highlighting in sources

---

## ğŸ“œ License

MIT License â€” free to use, modify, and extend.

---

## ğŸ™Œ Acknowledgements

* LangChain
* HuggingFace Sentence Transformers
* FAISS
* Streamlit

---

â­ If you find this project useful, consider starring the repo!
